{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eKL4_OaRXEeM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install mysql\n",
    "# !pip install mysql\n",
    "# !pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOMAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Gj7newviXb0k"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "df = pd.read_csv('domain_data.csv')\n",
    "domain_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for idx in df.index:\n",
    "    for dom in eval(df.loc[idx, 'Domains']):\n",
    "        domain_df = domain_df.append({'Name': df.loc[idx, 'Name'], 'Domains': dom.lower()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwo6NEYMcEQU",
    "outputId": "2136b09f-13b8-436d-b045-66e7012a4b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_df['Domains'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AF3WePcCcRFj"
   },
   "outputs": [],
   "source": [
    "def clean_domains_df(df):\n",
    "    df['Domains'].replace('image processing', 'computer vision', inplace=True)\n",
    "    df['Domains'].replace('machine learning & deep learning', 'deep learning', inplace=True)\n",
    "    df['Domains'].replace('machine learning algorithms', 'machine learning', inplace=True)\n",
    "    df['Domains'].replace('signals and systems', 'signal processing', inplace=True)\n",
    "    df.loc[df['Domains'].str.contains('signal processing'), 'Domains'] = 'signal processing'\n",
    "    df.loc[df['Domains'].str.contains('computer vision'), 'Domains'] = 'computer vision'\n",
    "    df.loc[df['Domains'].str.contains('audio'), 'Domains'] = 'audio processing'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j6Hv18_gecY",
    "outputId": "25de2de0-7dc4-4c57-c232-0ded15d8977a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_df = clean_domains_df(domain_df)\n",
    "domain_df['Domains'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ew8hxhhHgpVJ",
    "outputId": "51111d62-c6d2-4045-95d2-541f22035a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['computer vision', 'deep learning', 'signal processing',\n",
       "       'reinforcement learning', 'markov decision process',\n",
       "       'wireless communication', 'resource allocation',\n",
       "       'machine learning', 'audio processing', 'auditory neuroscience',\n",
       "       'biometrics & human computer interactions (hci)', 'vi',\n",
       "       'process engineering', 'separation process',\n",
       "       'mathematical biology', 'mathematical finance',\n",
       "       'computer networks', 'network security',\n",
       "       'distributions models and its applications',\n",
       "       'statistics and finance', 'nlp', 'clinical data mining',\n",
       "       'computational biology', 'complex system', 'collective behavior',\n",
       "       'dynamical system', 'statistical physics in biology', 'vlsi',\n",
       "       'hpc', 'semiconductor devices', 'iot', 'information retrieval',\n",
       "       'data mining', 'pattern recognition', 'applied mathematics',\n",
       "       'non-linear dynamics', 'healthcare', 'robotics', 'biomechanics',\n",
       "       'finite element analysis', 'optimization', 'implant design',\n",
       "       'surgical simulations', 'statistical inference', 'networks',\n",
       "       'algorithms', 'communications', 'learning algorithms',\n",
       "       'parallel processing', 'interconnetion networks',\n",
       "       'dynamic data assimilation', 'computational finance'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_df['Domains'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "oZDzGzoidZtp",
    "outputId": "d99170f0-8052-4f89-da89-79d64ead65c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_df.drop_duplicates(ignore_index=True, inplace=True)\n",
    "domain_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOI DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_folder_path = 'DBMS-Lab-main/publication_data'\n",
    "# ct = 0\n",
    "# ct1 = 0\n",
    "\n",
    "# for prof_file in sorted(os.listdir(paper_folder_path)):\n",
    "\n",
    "#     try:\n",
    "#         if prof_file.split('.')[-1] != 'csv': continue\n",
    "#         publication_df = pd.read_csv(os.path.join(paper_folder_path, prof_file))\n",
    "        \n",
    "#         for idx in publication_df.index:\n",
    "#             date = publication_df.loc[idx, 'Publication date']\n",
    "#             if isinstance(date, str):\n",
    "#                 if int(date.split('/')[0]) < 2018:\n",
    "#                     publication_df.drop(idx, axis='rows', inplace=True)\n",
    "#                     ct+=1\n",
    "#             ct1+=1\n",
    "#         publication_df.to_csv(paper_folder_path + '/' + prof_file, index=False)\n",
    "            \n",
    "#     except:\n",
    "#         print(prof_file + \" Failed\")\n",
    "        \n",
    "# print(ct)\n",
    "# print(ct1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 935,\n",
       " 'Authors': 842,\n",
       " 'Publication date': 686,\n",
       " 'Journal': 408,\n",
       " 'Volume': 301,\n",
       " 'Issue': 184,\n",
       " 'Publisher': 536,\n",
       " 'Description': 832,\n",
       " 'Total citations': 935,\n",
       " 'Scholar articles': 853,\n",
       " 'Citation Count': 935,\n",
       " 'Pages': 554,\n",
       " 'Conference': 198,\n",
       " 'Book': 35,\n",
       " 'Inventors': 11,\n",
       " 'Patent office': 11,\n",
       " 'Patent number': 7,\n",
       " 'Application number': 11,\n",
       " 'Institution': 5,\n",
       " 'Source': 18,\n",
       " 'Report number': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_folder_path = 'DBMS-Lab-main/publication_data'\n",
    "\n",
    "paper_col_count = {}\n",
    "# ct = 0\n",
    "\n",
    "for prof_file in sorted(os.listdir(paper_folder_path)):\n",
    "\n",
    "    try:\n",
    "        if prof_file.split('.')[-1] != 'csv': continue\n",
    "        publication_df = pd.read_csv(os.path.join(paper_folder_path, prof_file))\n",
    "#         ct += len(publication_df)\n",
    "        \n",
    "        for col in publication_df.columns:\n",
    "            if col in paper_col_count:\n",
    "                paper_col_count[col] += publication_df[col].notna().sum()\n",
    "            else:\n",
    "                paper_col_count[col] = 0\n",
    "                \n",
    "    \n",
    "    except:\n",
    "        print(prof_file + \" Failed\")\n",
    "        \n",
    "# print(f\"Num of Papers: {ct}\")\n",
    "paper_col_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all into published_in column with publication_type column as well\n",
    "publication_columns = ['Journal', 'Conference', 'Patent office', 'Book']\n",
    "\n",
    "# Combines both into authors column, basically got rid of inventors columns by merging it\n",
    "writer_columns = ['Authors', 'Inventors']\n",
    "\n",
    "# These columns are dropped\n",
    "drop_columns = ['Volume', 'Issue', 'Pages', 'Patent number', 'Application number', \n",
    "             'Institution', 'Source', 'Report number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_publications_df(publication_df):\n",
    "    \n",
    "        ###----------------Drop excess columns----------------###\n",
    "        drop_col = list(set(publication_df.columns) & set(drop_columns))\n",
    "        publication_df.drop(drop_col, axis='columns', inplace=True)\n",
    "        \n",
    "        ###----------------Combine publication columns----------------###\n",
    "        \n",
    "        publication_df['Published_in'] = ''\n",
    "        publication_df['Publication_type'] = ''\n",
    "        \n",
    "        # Created published_in column\n",
    "        publication_cols = list(set(publication_df.columns) & set(publication_columns))\n",
    "        for col in publication_cols:\n",
    "            publication_df['Published_in'] += publication_df[col].fillna('')\n",
    "        \n",
    "        # Created publication_type column\n",
    "        publication_df[publication_cols] = publication_df[publication_cols].notna() * publication_cols\n",
    "        for col in publication_cols:\n",
    "            publication_df['Publication_type'] += publication_df[col]\n",
    "            \n",
    "        publication_df.drop(publication_cols, axis='columns', inplace=True)\n",
    "        \n",
    "        ###----------------Combine authors columns----------------###\n",
    "        \n",
    "        publication_df['AUTHORS'] = ''\n",
    "        \n",
    "        author_cols = list(set(publication_df.columns) & set(writer_columns))\n",
    "        for col in author_cols:\n",
    "            publication_df['AUTHORS'] += publication_df[col].fillna('')\n",
    "            \n",
    "        publication_df.drop(author_cols, axis='columns', inplace=True)\n",
    "        publication_df.rename(columns = {'AUTHORS':'Authors'}, inplace = True)\n",
    "        \n",
    "        ###----------------Publication date column----------------###\n",
    "        \n",
    "        def date2year(dt):\n",
    "            if isinstance(dt, str): \n",
    "                return dt.split('/')[0]\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        publication_df['Publication date'] = publication_df['Publication date'].apply(lambda dt : date2year(dt))\n",
    "        publication_df = publication_df.astype({'Publication date':int})\n",
    "        publication_df.rename(columns = {'Publication date':'Publication year'}, inplace = True)\n",
    "    \n",
    "        ###----------------Yearwise Citation columns----------------###\n",
    "        \n",
    "        years = ['2018', '2019', '2020', '2021', '2022', '2023']\n",
    "        for idx in publication_df.index:\n",
    "            year_dict = eval(publication_df.loc[idx, 'Citation Count'])\n",
    "            for year in years:\n",
    "                if year in year_dict:\n",
    "                    publication_df.loc[idx, year + '_citations'] = year_dict[year]\n",
    "                else:\n",
    "                    publication_df.loc[idx, year + '_citations'] = 0\n",
    "                    \n",
    "        publication_df.drop('Citation Count', axis='columns', inplace=True)\n",
    "        for year in years:\n",
    "            publication_df = publication_df.astype({year+'_citations':int})\n",
    "        \n",
    "        ###----------------Fixing column names----------------###\n",
    "        \n",
    "        for col in publication_df.columns:\n",
    "            if ' ' in col:\n",
    "                new_name = '_'.join(col.split(' '))\n",
    "                publication_df.rename(columns = {col:new_name}, inplace = True)\n",
    "        \n",
    "        return publication_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication_year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Description</th>\n",
       "      <th>Total_citations</th>\n",
       "      <th>Scholar_articles</th>\n",
       "      <th>Published_in</th>\n",
       "      <th>Publication_type</th>\n",
       "      <th>Authors</th>\n",
       "      <th>2018_citations</th>\n",
       "      <th>2019_citations</th>\n",
       "      <th>2020_citations</th>\n",
       "      <th>2021_citations</th>\n",
       "      <th>2022_citations</th>\n",
       "      <th>2023_citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence Interval Construction for Multivari...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we propose a novel procedure to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Confidence Interval Construction for Multivari...</td>\n",
       "      <td>arXiv preprint arXiv:2211.13915</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Aryan Bhambu, Arabin Kumar Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrated Brier Score based Survival Cobra--A...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we provide two novel regression...</td>\n",
       "      <td>0</td>\n",
       "      <td>Integrated Brier Score based Survival Cobra--A...</td>\n",
       "      <td>arXiv preprint arXiv:2210.12006</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Rahul Goswami, Arabin Kumar Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Controlling Travel Path of Original Cobra</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we propose a kernel based COBRA ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Controlling Travel Path of Original Cobra\\nMB ...</td>\n",
       "      <td>arXiv preprint arXiv:2210.10655</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Mriganka Basu RoyChowdhury, Arabin K Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Controlling Travel Path of Original Cobra</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we propose a kernel based COBRA ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Controlling Travel Path of Original Cobra\\nM B...</td>\n",
       "      <td>arXiv e-prints</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Mriganka Basu RoyChowdhury, Arabin K Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concordance based Survival Cobra with regressi...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we predict conditional survival...</td>\n",
       "      <td>0</td>\n",
       "      <td>Concordance based Survival Cobra with regressi...</td>\n",
       "      <td>arXiv preprint arXiv:2209.11919</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Rahul Goswami, Arabin Kumar Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Modeling long-term groundwater levels by explo...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Springer Netherlands</td>\n",
       "      <td>Inevitable issues concerning the sustainabilit...</td>\n",
       "      <td>10</td>\n",
       "      <td>Modeling long-term groundwater levels by explo...</td>\n",
       "      <td>Water Resources Management</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Sangita Dey, Arabin Kumar Dey, Rajesh Kumar Mall</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Construction of confidence interval for a univ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Springer Berlin Heidelberg</td>\n",
       "      <td>In this paper, we show an innovative way to co...</td>\n",
       "      <td>5</td>\n",
       "      <td>Construction of confidence interval for a univ...</td>\n",
       "      <td>Annals of Data Science</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Shankhajyoti De, Arabin Kumar Dey, Deepak Kuma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Some Variations of EM Algorithms for Marshall–...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Springer International Publishing</td>\n",
       "      <td>Recently, Asimit et al. have used an EM algori...</td>\n",
       "      <td>3</td>\n",
       "      <td>Some Variations of EM Algorithms for Marshall–...</td>\n",
       "      <td>Journal of Statistical Theory and Practice</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Arabin Kumar Dey, Biplab Paul</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fate of Snakes in an Urban Landscape-A report ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Fate of Snakes in an Urban Landscape-A report ...</td>\n",
       "      <td>Reptile Rap</td>\n",
       "      <td>Journal</td>\n",
       "      <td>D Gayen, S Dey, AK Dey, US Roy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fate of Snakes in an Urban Landscape-A</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Materials and Methods\\nStudy Site: The present...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fate of Snakes in an Urban Landscape-A\\nD Gaye...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D Gayen, S Dey, AK Dey, US Roy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayesian analysis of absolute continuous Marsh...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper provides two different novel approa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bayesian analysis of absolute continuous Marsh...</td>\n",
       "      <td>arXiv preprint arXiv:1809.06405</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Biplab Paul, Arabin Kumar Dey, Sanku Dey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Parameter Estimation of absolute continuous fo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we formulate a four parameter ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Parameter Estimation of absolute continuous fo...</td>\n",
       "      <td>arXiv preprint arXiv:1809.06052</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Biplab Paul, Arabin Kumar Dey, Arjun K Gupta, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A novel empirical bayes with reversible jump m...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this article we select the unknown dimensio...</td>\n",
       "      <td>1</td>\n",
       "      <td>A novel empirical bayes with reversible jump m...</td>\n",
       "      <td>arXiv preprint arXiv:1808.05480</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Arabin Kumar Dey, Himanshu Jhamb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bayesian analysis of three parameter absolute ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Taylor &amp; Francis</td>\n",
       "      <td>This paper provides Bayesian analysis of absol...</td>\n",
       "      <td>5</td>\n",
       "      <td>Bayesian analysis of three parameter absolute ...</td>\n",
       "      <td>Communications in Statistics: Case Studies, Da...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Biplab Paul, Arabin Kumar Dey, Debasis Kundu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>An EM algorithm for absolute continuous bivari...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recently Asimit et. al ([4]) and Dey ([6]) use...</td>\n",
       "      <td>6</td>\n",
       "      <td>An EM algorithm for absolute continuous bivari...</td>\n",
       "      <td>arXiv preprint arXiv:1608.02199 v4 [Stat. CO]</td>\n",
       "      <td>Journal</td>\n",
       "      <td>Arabin Kumar Dey, B Paul, D Kundu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Publication_year  \\\n",
       "0   Confidence Interval Construction for Multivari...              2022   \n",
       "1   Integrated Brier Score based Survival Cobra--A...              2022   \n",
       "2           Controlling Travel Path of Original Cobra              2022   \n",
       "3           Controlling Travel Path of Original Cobra              2022   \n",
       "4   Concordance based Survival Cobra with regressi...              2022   \n",
       "5   Modeling long-term groundwater levels by explo...              2021   \n",
       "6   Construction of confidence interval for a univ...              2020   \n",
       "7   Some Variations of EM Algorithms for Marshall–...              2019   \n",
       "8   Fate of Snakes in an Urban Landscape-A report ...              2019   \n",
       "9              Fate of Snakes in an Urban Landscape-A              2019   \n",
       "10  Bayesian analysis of absolute continuous Marsh...              2018   \n",
       "11  Parameter Estimation of absolute continuous fo...              2018   \n",
       "12  A novel empirical bayes with reversible jump m...              2018   \n",
       "13  Bayesian analysis of three parameter absolute ...              2018   \n",
       "14  An EM algorithm for absolute continuous bivari...              2018   \n",
       "\n",
       "                            Publisher  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "5                Springer Netherlands   \n",
       "6          Springer Berlin Heidelberg   \n",
       "7   Springer International Publishing   \n",
       "8                                 NaN   \n",
       "9                                 NaN   \n",
       "10                                NaN   \n",
       "11                                NaN   \n",
       "12                                NaN   \n",
       "13                   Taylor & Francis   \n",
       "14                                NaN   \n",
       "\n",
       "                                          Description  Total_citations  \\\n",
       "0   In this paper we propose a novel procedure to ...                0   \n",
       "1   In this paper, we provide two novel regression...                0   \n",
       "2   In this paper we propose a kernel based COBRA ...                0   \n",
       "3   In this paper we propose a kernel based COBRA ...                0   \n",
       "4   In this paper, we predict conditional survival...                0   \n",
       "5   Inevitable issues concerning the sustainabilit...               10   \n",
       "6   In this paper, we show an innovative way to co...                5   \n",
       "7   Recently, Asimit et al. have used an EM algori...                3   \n",
       "8                                                 NaN                6   \n",
       "9   Materials and Methods\\nStudy Site: The present...                0   \n",
       "10  This paper provides two different novel approa...                0   \n",
       "11  In this paper we formulate a four parameter ab...                0   \n",
       "12  In this article we select the unknown dimensio...                1   \n",
       "13  This paper provides Bayesian analysis of absol...                5   \n",
       "14  Recently Asimit et. al ([4]) and Dey ([6]) use...                6   \n",
       "\n",
       "                                     Scholar_articles  \\\n",
       "0   Confidence Interval Construction for Multivari...   \n",
       "1   Integrated Brier Score based Survival Cobra--A...   \n",
       "2   Controlling Travel Path of Original Cobra\\nMB ...   \n",
       "3   Controlling Travel Path of Original Cobra\\nM B...   \n",
       "4   Concordance based Survival Cobra with regressi...   \n",
       "5   Modeling long-term groundwater levels by explo...   \n",
       "6   Construction of confidence interval for a univ...   \n",
       "7   Some Variations of EM Algorithms for Marshall–...   \n",
       "8   Fate of Snakes in an Urban Landscape-A report ...   \n",
       "9   Fate of Snakes in an Urban Landscape-A\\nD Gaye...   \n",
       "10  Bayesian analysis of absolute continuous Marsh...   \n",
       "11  Parameter Estimation of absolute continuous fo...   \n",
       "12  A novel empirical bayes with reversible jump m...   \n",
       "13  Bayesian analysis of three parameter absolute ...   \n",
       "14  An EM algorithm for absolute continuous bivari...   \n",
       "\n",
       "                                         Published_in Publication_type  \\\n",
       "0                     arXiv preprint arXiv:2211.13915          Journal   \n",
       "1                     arXiv preprint arXiv:2210.12006          Journal   \n",
       "2                     arXiv preprint arXiv:2210.10655          Journal   \n",
       "3                                      arXiv e-prints          Journal   \n",
       "4                     arXiv preprint arXiv:2209.11919          Journal   \n",
       "5                          Water Resources Management          Journal   \n",
       "6                              Annals of Data Science          Journal   \n",
       "7          Journal of Statistical Theory and Practice          Journal   \n",
       "8                                         Reptile Rap          Journal   \n",
       "9                                                                        \n",
       "10                    arXiv preprint arXiv:1809.06405          Journal   \n",
       "11                    arXiv preprint arXiv:1809.06052          Journal   \n",
       "12                    arXiv preprint arXiv:1808.05480          Journal   \n",
       "13  Communications in Statistics: Case Studies, Da...          Journal   \n",
       "14      arXiv preprint arXiv:1608.02199 v4 [Stat. CO]          Journal   \n",
       "\n",
       "                                              Authors  2018_citations  \\\n",
       "0                      Aryan Bhambu, Arabin Kumar Dey               0   \n",
       "1                     Rahul Goswami, Arabin Kumar Dey               0   \n",
       "2            Mriganka Basu RoyChowdhury, Arabin K Dey               0   \n",
       "3            Mriganka Basu RoyChowdhury, Arabin K Dey               0   \n",
       "4                     Rahul Goswami, Arabin Kumar Dey               0   \n",
       "5    Sangita Dey, Arabin Kumar Dey, Rajesh Kumar Mall               0   \n",
       "6   Shankhajyoti De, Arabin Kumar Dey, Deepak Kuma...               0   \n",
       "7                       Arabin Kumar Dey, Biplab Paul               3   \n",
       "8                      D Gayen, S Dey, AK Dey, US Roy               0   \n",
       "9                      D Gayen, S Dey, AK Dey, US Roy               0   \n",
       "10           Biplab Paul, Arabin Kumar Dey, Sanku Dey               0   \n",
       "11  Biplab Paul, Arabin Kumar Dey, Arjun K Gupta, ...               0   \n",
       "12                   Arabin Kumar Dey, Himanshu Jhamb               0   \n",
       "13       Biplab Paul, Arabin Kumar Dey, Debasis Kundu               0   \n",
       "14                  Arabin Kumar Dey, B Paul, D Kundu               1   \n",
       "\n",
       "    2019_citations  2020_citations  2021_citations  2022_citations  \\\n",
       "0                0               0               0               0   \n",
       "1                0               0               0               0   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "5                0               0               0               5   \n",
       "6                0               0               1               3   \n",
       "7                0               0               0               0   \n",
       "8                0               0               0               4   \n",
       "9                0               0               0               0   \n",
       "10               0               0               0               0   \n",
       "11               0               0               0               0   \n",
       "12               0               1               0               0   \n",
       "13               0               0               0               0   \n",
       "14               1               2               2               0   \n",
       "\n",
       "    2023_citations  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "5                5  \n",
       "6                1  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_sql_columns = []\n",
    "\n",
    "for prof_file in sorted(os.listdir(paper_folder_path)):\n",
    "\n",
    "    try:\n",
    "        if prof_file.split('.')[-1] != 'csv':\n",
    "            continue\n",
    "            \n",
    "        publication_df = pd.read_csv(os.path.join(paper_folder_path, prof_file))\n",
    "        \n",
    "        publication_df = reformat_publications_df(publication_df)\n",
    "        pub_sql_columns.extend(publication_df.columns)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except:\n",
    "        print(prof_file + \" Failed\")\n",
    "                \n",
    "pub_sql_columns = list(set(pub_sql_columns))\n",
    "\n",
    "publication_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"research_db_admin\",\n",
    "  password=\"1234\",\n",
    "  database=\"ResearchPortalDB\"\n",
    ")\n",
    "\n",
    "db_cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_folder_path = 'DBMS-Lab-main/prof_data'\n",
    "prof_data = pd.DataFrame(columns = ['Name', 'citations_all', 'citations_after2018', 'i10_index_all', 'i10_index_after2018', 'h_index_all', 'h_index_after2018', 'position', 'department', 'position_in_DSAI'])\n",
    "prof_text_cols = ['Name', 'position', 'department', 'position_in_DSAI']\n",
    "\n",
    "prof_pos_df = pd.read_csv('faculty.csv')\n",
    "prof_pos_df['Position in DSAI'] = prof_pos_df['Position in DSAI'].str.replace('head', 'head of the school')\n",
    "prof_pos_df['Position in DSAI'] = prof_pos_df['Position in DSAI'].str.replace('assoc_faculty_list', 'associated faculty')\n",
    "prof_pos_df['Position in DSAI'] = prof_pos_df['Position in DSAI'].str.replace('distinguished_faculty', 'distinguished faculty')\n",
    "\n",
    "###----------------Making Prof_data DataFrame----------------###\n",
    "idx = 0 \n",
    "for prof in sorted(os.listdir(prof_folder_path)):\n",
    "    \n",
    "    if prof.split('.')[-1] != 'csv':\n",
    "        continue\n",
    "\n",
    "    if prof == 'domain_data.csv':\n",
    "        continue\n",
    "\n",
    "    prof_df = pd.read_csv(os.path.join(prof_folder_path, prof)).set_index('Index')\n",
    "    name = ' '.join(prof.replace('.csv', '').split('_'))\n",
    "    \n",
    "    prof_data.loc[idx, 'Name'] = name\n",
    "    prof_data.loc[idx, 'citations_all'] = prof_df.loc['Citations', 'All']\n",
    "    prof_data.loc[idx, 'citations_after2018'] = prof_df.loc['Citations', 'Since 2018']\n",
    "    prof_data.loc[idx, 'i10_index_all'] = prof_df.loc['i10-index', 'All']\n",
    "    prof_data.loc[idx, 'i10_index_after2018'] = prof_df.loc['i10-index', 'Since 2018']\n",
    "    prof_data.loc[idx, 'h_index_all'] = prof_df.loc['h-index', 'All']\n",
    "    prof_data.loc[idx, 'h_index_after2018'] = prof_df.loc['h-index', 'Since 2018']\n",
    "    prof_data.loc[idx, 'position'] = prof_pos_df.loc[prof_pos_df['Name'] == name, 'Position'].squeeze().split(', ')[0]\n",
    "    prof_data.loc[idx, 'department'] = prof_pos_df.loc[prof_pos_df['Name'] == name, 'Position'].squeeze().split(', ')[1]\n",
    "    prof_data.loc[idx, 'position_in_DSAI'] = prof_pos_df.loc[prof_pos_df['Name'] == name, 'Position in DSAI'].squeeze()\n",
    "   \n",
    "    idx += 1\n",
    "    \n",
    "    \n",
    "###----------------Creating Professors SQL Table----------------###\n",
    "\n",
    "column_cmd = \"\"\n",
    "for col in prof_data.columns:\n",
    "    if col in prof_text_cols:\n",
    "        column_cmd += f\"{col} text, \"\n",
    "    else:\n",
    "        column_cmd += f\"{col} int, \"\n",
    "    \n",
    "publications_table_command = f'CREATE TABLE professors (ProfID int NOT NULL AUTO_INCREMENT, PRIMARY KEY (ProfID), {column_cmd});'.replace(', )', ')')\n",
    "db_cursor.execute(publications_table_command)\n",
    "db_cursor.execute('ALTER TABLE professors AUTO_INCREMENT=2100;')\n",
    "\n",
    "###----------------Uploading to Professors SQL Table----------------###\n",
    "\n",
    "for idx in prof_data.index:\n",
    "    \n",
    "    col_names = \"\"\n",
    "    values = \"\"\n",
    "    for col in prof_data.columns:\n",
    "        col_names += f\"{col}, \"\n",
    "        values += f\"\\\"{prof_data.loc[idx, col]}\\\", \"\n",
    "        \n",
    "    upload_command = f\"INSERT INTO professors({col_names}) VALUES ({values});\".replace(', )', ')')\n",
    "    db_cursor.execute(upload_command)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_columns = ['Publication_year', '2018_citations', '2019_citations', '2020_citations', '2021_citations', '2022_citations', '2023_citations', 'Total_citations']\n",
    "\n",
    "def create_publication_sql(pub_sql_columns, integer_columns):\n",
    "    \n",
    "    column_cmd = \"\"\n",
    "    for col in pub_sql_columns:\n",
    "        if col  not in integer_columns:\n",
    "            column_cmd += f\"{col} text, \"\n",
    "    \n",
    "    for col in integer_columns:\n",
    "        column_cmd += f\"{col} int, \"\n",
    "        \n",
    "    publications_table_command = f'CREATE TABLE publications (PaperID int NOT NULL AUTO_INCREMENT, PRIMARY KEY (PaperID), {column_cmd});'.replace(', )', ')')\n",
    "\n",
    "    db_cursor.execute(publications_table_command)\n",
    "    db_cursor.execute('ALTER TABLE publications AUTO_INCREMENT=11000;')\n",
    "    \n",
    "def create_author_relation_sql():\n",
    "\n",
    "    auth_reln_command = \"CREATE TABLE author_relations (ProfID int, PaperID int)\"\n",
    "    db_cursor.execute(auth_reln_command)\n",
    "    \n",
    "def create_coauthor_sql():\n",
    "\n",
    "    coauth_command = \"CREATE TABLE coauthors (PaperID int, Author text)\"\n",
    "    db_cursor.execute(coauth_command)\n",
    "    \n",
    "create_publication_sql(pub_sql_columns, integer_columns)\n",
    "create_author_relation_sql()\n",
    "create_coauthor_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_publication_df(prof_file, df):\n",
    "    \n",
    "#     try:\n",
    "        col_names = ''\n",
    "        for col in df.columns:\n",
    "            col_names += f'{col}, '\n",
    "            \n",
    "        # ProfID Querying    \n",
    "        prof_name = ' '.join(prof_file.replace('.csv', '').split('_'))\n",
    "        prof_id_query = f\"SELECT ProfID FROM professors WHERE (Name = \\\"{prof_name}\\\")\"\n",
    "        db_cursor.execute(prof_id_query)\n",
    "        prof_id = db_cursor.fetchall()[0][0]\n",
    "        \n",
    "        for idx in df.index:\n",
    "            \n",
    "            ## Create query and update command for author relation table and publication table\n",
    "            values = ''\n",
    "            query_condition = ''\n",
    "            for col in df.columns:\n",
    "                \n",
    "                if(isinstance(df.loc[idx, col], str)):\n",
    "                    df.loc[idx, col] = df.loc[idx, col].replace('\"', \"'\")\n",
    "                    df.loc[idx, col] = df.loc[idx, col].replace(\"\\\\\", \"\")\n",
    "                    df.loc[idx, col] = df.loc[idx, col].replace(\"\\n\", \" \")\n",
    "                    \n",
    "                query_condition += f\" ({col} = \\\"{df.loc[idx, col]}\\\") AND\"\n",
    "                values += f\"\\\"{df.loc[idx, col]}\\\", \"\n",
    "            \n",
    "            record_query = f\"SELECT PaperID FROM publications WHERE ({query_condition})\".replace('AND)', ')')\n",
    "            update_command = f\"INSERT INTO publications({col_names}) VALUES ({values})\".replace(', )', ')')\n",
    "            \n",
    "            db_cursor.execute(record_query)\n",
    "            query_result = db_cursor.fetchall()\n",
    "            if len(query_result) == 0:\n",
    "                db_cursor.execute(update_command)\n",
    "                mydb.commit()\n",
    "                \n",
    "                db_cursor.execute(\"SELECT MAX(PaperID) FROM publications\")\n",
    "                paper_id = db_cursor.fetchall()[0][0] + 1\n",
    "\n",
    "            else:\n",
    "                paper_id = query_result[0][0]\n",
    "                \n",
    "            db_cursor.execute(f\"INSERT INTO author_relations(ProfID, PaperID) VALUES ({prof_id}, {paper_id})\")\n",
    "            mydb.commit()\n",
    "            \n",
    "            ## Update coauthor table\n",
    "            \n",
    "            auths = df.loc[idx, 'Authors'].split(', ')\n",
    "            for auth in auths:\n",
    "                coauth_cmd = f\"INSERT INTO coauthors(PaperID, Author) VALUES ({paper_id}, \\\"{auth}\\\");\"\n",
    "                db_cursor.execute(coauth_cmd)\n",
    "                mydb.commit()\n",
    "                \n",
    "#     except:\n",
    "#         print(str(df.loc[idx, 'Title']) + \"  \" + prof_file)\n",
    "#         print(update_command)\n",
    "#         print()\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "all_df = pd.DataFrame()\n",
    "for prof_file in sorted(os.listdir(paper_folder_path)):\n",
    "\n",
    "#     try:\n",
    "        if prof_file.split('.')[-1] != 'csv':\n",
    "            continue\n",
    "            \n",
    "        publication_df = pd.read_csv(os.path.join(paper_folder_path, prof_file))\n",
    "        publication_df = reformat_publications_df(publication_df)\n",
    "        update_publication_df(prof_file, publication_df)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "#     except:\n",
    "#         print(prof_file + \" Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df[all_df['Title'] == 'Automatic syllabification for manipuri language']\n",
    "# # all_df[all_df['Title'] == 'Comparison of floating-point representations for the efficient implementation of machine learning algorithms']\n",
    "# len(all_df[['Title', 'Authors', 'Published_in']].value_counts().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_table_sql():\n",
    "\n",
    "    domain_table_command = \"CREATE TABLE domains (ProfID int, Domains text)\"\n",
    "    db_cursor.execute(domain_table_command)\n",
    "    \n",
    "    for idx in domain_df.index:\n",
    "        try:\n",
    "            prof_name = domain_df.loc[idx, 'Name']\n",
    "            prof_id_query = f\"SELECT ProfID FROM professors WHERE (Name = \\\"{prof_name}\\\")\"\n",
    "            db_cursor.execute(prof_id_query)\n",
    "            prof_id = db_cursor.fetchall()[0][0]\n",
    "\n",
    "            domain_update_command = f\"INSERT INTO domains(ProfID, Domains) VALUES ({prof_id}, \\\"{domain_df.loc[idx, 'Domains']}\\\")\"\n",
    "            db_cursor.execute(domain_update_command)\n",
    "            mydb.commit()\n",
    "        except:\n",
    "            print(prof_name + \" Failed\")\n",
    "        \n",
    "create_domain_table_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
